1) Hadoop in layman's term:
Apache Hadoop is an open source framework which provides an automated distributed computing environment that supports storage of big data sets. It does that storage using a cluster of commodity machines. It then analyses this stored big data using a very simple programming model. The storage mechanism is known as HDFS (Hadoop Distributed File System). It is based on google GFS(Google File System) white paper. The analytical mechanism is known as Map Reduce and is based on google map reduce white paper.

2) Hadoop framework:
The Apache Hadoop framework is composed of the following modules:

Hadoop Common – The common module contains libraries and utilities which are required by other modules of Hadoop.
Hadoop Distributed File System (HDFS) – This is the distributed file-system which stores data on the commodity machines. This is the core of the hadoop framework. This also provides a very high aggregate bandwidth across the cluster.
Hadoop YARN – This is the resource-management platform which is responsible for managing computer resources over the clusters and using them for scheduling of users' applications.
Hadoop MapReduce – This is the programming model used for large scale data processing.
All of these modules in Hadoop are designed with a fundamental assumption that hardware failures (of individual machines or racks of machines) are common and should be capable of automatically handling the software by the framework. Apache Hadoop's MapReduce and HDFS components are originally derived from the Google's MapReduce and Google File System (GFS) respectively.

The Hadoop Distributed File System or the HDFS is a distributed file system that runs on commodity hardware. It is very similar to any existing distributed file system. However, there are significant differences from other distributed file systems. HDFS is designed to be highly fault-tolerant and can be deployed on a low-cost hardware. It also provides high throughput access to application data and is suitable to handle applications that have large data sets.

3) Reasons to learn big data:
Business reasons:
  New style of IT emerging.
  Demand for big data skills is so high.
Personal reasons:
  New job
  Skill development
  To earn more and to be a part of an emerging technology.
